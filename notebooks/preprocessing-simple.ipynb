{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Images to generate a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  Could not find a version that satisfies the requirement cv2 (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for cv2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from datetime import datetime as dt\n",
    "from multiprocessing import Pool\n",
    "from skimage.io import imread\n",
    "from tensorflow.keras.applications import vgg16\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/jovyan/work/image-classifier/bigdata-217213-55b1dfc31b66.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://bigdata-allanbatista-com-br/trainer/20181110_183306/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepath = 'gs://bigdata-allanbatista-com-br/trainer/{}/'.format(dt.now().strftime('%Y%m%d_%H%M%S'))\n",
    "basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = storage.Client()\n",
    "bucket = gs.bucket('bigdata-allanbatista-com-br')\n",
    "\n",
    "def list_blobs(pattern):\n",
    "    return [blob.name for blob in bucket.list_blobs(prefix=pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images_with_labels(pattern):\n",
    "    x = []\n",
    "    y = []\n",
    "    for path in list_blobs(pattern):\n",
    "        x.append(path)\n",
    "        y.append(path.split(\"/\")[2])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, labels = list_images_with_labels(\"dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = LabelBinarizer()\n",
    "y_train = binarizer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_io.FileIO('{}binarizer.pickle'.format(basepath), 'wb+') as f:\n",
    "    f.write(pickle.dumps(binarizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56,  64,  67, ..., 120, 129, 112], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = 'gs://bigdata-allanbatista-com-br/{}'.format(paths[0])\n",
    "# with file_io.FileIO(filename, 'rb') as file:\n",
    "#     image = imread(file)\n",
    "\n",
    "# np.reshape(np.array(image), (len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck_size = 10\n",
    "fff = None\n",
    "\n",
    "def create_record(features, label):\n",
    "    features = tf.train.Features(feature={\n",
    "        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=label)),\n",
    "        'features': tf.train.Feature(bytes_list=tf.train.BytesList(value=[features.tostring()]))\n",
    "    })\n",
    "    \n",
    "    return tf.train.Example(features=features)\n",
    "\n",
    "def read_image(path):\n",
    "    filename = 'gs://bigdata-allanbatista-com-br/{}'.format(path)\n",
    "\n",
    "    with file_io.FileIO(filename, 'rb') as file:\n",
    "        image = imread(file)\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def create_and_write_record(data, x, y, dest_path):\n",
    "    i = data[0]\n",
    "    index = data[1]\n",
    "    start = dt.now()\n",
    "    filename = \"{}{}.tfrecord\".format(dest_path, str(index).zfill(5))\n",
    "    \n",
    "    with Pool(10) as p:\n",
    "        images = np.array(p.map(read_image, x[i:i+chunck_size]))\n",
    "    \n",
    "    features = np.reshape(images, (len(images), 256 * 256 * 3))\n",
    "\n",
    "    print(features.shape)\n",
    "    \n",
    "    print(\"writing in doc\")\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for feature, label in zip(images, y[i:i+chunck_size]):\n",
    "            record = create_record(feature, label)\n",
    "            writer.write(record.SerializeToString())            \n",
    "\n",
    "    print(\"diff %ds: %s\" % ((dt.now() - start).total_seconds(), filename))\n",
    "\n",
    "    \n",
    "def create_dataset_to_gs(x, y, dest_path):\n",
    "    chunck_i = list(range(0, len(y), chunck_size))\n",
    "    chunck_index = list(range(len(chunck_i)))\n",
    "\n",
    "    for data in list(zip(chunck_i, chunck_index)):\n",
    "        print(\"create first chunck\")\n",
    "        create_and_write_record(data, x, y, dest_path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create first chunck\n",
      "(10, 196608)\n",
      "writing in doc\n",
      "diff 2s: gs://bigdata-allanbatista-com-br/trainer/20181110_183306/trainset_simple/00000.tfrecord\n"
     ]
    }
   ],
   "source": [
    "create_dataset_to_gs(paths, y_train, \"{}trainset_simple/\".format(basepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196608,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshapeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
